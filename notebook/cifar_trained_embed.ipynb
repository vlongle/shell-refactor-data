{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 19:08:39.900592: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 19:08:40.498664: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-17 19:08:40.498714: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-17 19:08:40.498719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rich.logging import RichHandler\n",
    "import logging\n",
    "from lightning_lite.utilities.seed import seed_everything\n",
    "from shell_data.dataset.dataset import get_train_val_test_subsets\n",
    "import torch\n",
    "import os\n",
    "from shell_data.utils.config import (\n",
    "    ShELLDataSharingConfig,\n",
    "    DatasetConfig,\n",
    "    TaskModelConfig,\n",
    "    TrainingConfig,\n",
    ")\n",
    "from shell_data.shell_agent.shell_agent_classification import ShELLClassificationAgent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import trimap\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(X):\n",
    "    return X.view(X.size(0), -1)\n",
    "\n",
    "def dist(X, X2, p=2):\n",
    "    return torch.cdist(to_features(X), to_features(X2), p=p)\n",
    "\n",
    "def get_xy(dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset))\n",
    "    return next(iter(dataloader))\n",
    "\n",
    "def cifar10_to_backbone_embedding(model, X):\n",
    "    # with torch.no_grad():\n",
    "    #     return model(X)\n",
    "    batch_size = 128\n",
    "    dataloader = torch.utils.data.DataLoader(X, batch_size=batch_size)\n",
    "    embeddings = []\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            embeddings.append(model(batch))\n",
    "    return torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar10\"\n",
    "train_subsets, val_subsets, test_subsets = get_train_val_test_subsets(\n",
    "    dataset_name)\n",
    "size = 512\n",
    "num_cls_per_task = 2\n",
    "\n",
    "cfg = ShELLDataSharingConfig(\n",
    "    n_agents=1,\n",
    "    dataset=DatasetConfig(\n",
    "        name=dataset_name,\n",
    "        train_size=size,\n",
    "        val_size=min(size, min([len(d) for d in val_subsets])),\n",
    "        num_task_per_life=1,\n",
    "        num_cls_per_task=num_cls_per_task,\n",
    "    ),\n",
    "    task_model=TaskModelConfig(\n",
    "        name=dataset_name,\n",
    "    ),\n",
    "    training=TrainingConfig(\n",
    "        n_epochs=100,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"{dataset_name}_128_2.pt\"\n",
    "buffer_name = f\"{dataset_name}_buffer\"\n",
    "\n",
    "# model_name = f\"{dataset_name}_128_10.pt\"\n",
    "# buffer_name = f\"{dataset_name}_10_buffer\"\n",
    "\n",
    "receiver = ShELLClassificationAgent(\n",
    "        train_subsets, val_subsets, test_subsets, cfg,\n",
    "        enable_validate_config=False,)\n",
    "receiver.load_model(model_name)\n",
    "receiver.load_buffer(buffer_name)\n",
    "print(\"buffer len:\", [len(b) for b in receiver.buffer.buffers])\n",
    "print(\"past tasks:\", receiver.buffer.past_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = ShELLClassificationAgent(\n",
    "        train_subsets, val_subsets, test_subsets, cfg,\n",
    "        enable_validate_config=False,)\n",
    "sender.ll_dataset.perm = torch.tensor([5, 7])  # should send 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_data = sender.ll_dataset.get_train_dataset(0)\n",
    "receiver_data = receiver.ll_dataset.get_train_dataset(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some random images from sender_data\n",
    "n_samples = 5\n",
    "fig, ax = plt.subplots(1, n_samples, figsize=(10, 10))\n",
    "for i in range(n_samples):\n",
    "    random_idx = np.random.randint(0, len(sender_data))\n",
    "    ax[i].imshow(sender_data[random_idx][0].permute(1, 2, 0))\n",
    "    ax[i].set_title(f\"Label: {sender_data[random_idx][1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some random images from receiver_data\n",
    "n_samples = 10\n",
    "fig, ax = plt.subplots(1, n_samples, figsize=(10, 10))\n",
    "for i in range(n_samples):\n",
    "    random_idx = np.random.randint(0, len(receiver_data))\n",
    "    ax[i].imshow(receiver_data[random_idx][0].permute(1, 2, 0))\n",
    "    ax[i].set_title(f\"Label: {receiver_data[random_idx][1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\"feats\":[]}\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name].append(output.detach())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = receiver.model.net\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.fcs[0].register_forward_hook(get_features(\"feats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone.conv_layers.register_forward_hook(get_features('feats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap.parametric_umap import ParametricUMAP\n",
    "clustering = \"param_umap\"\n",
    "# clustering = \"umap\"\n",
    "# clustering = \"tsne\"\n",
    "# clustering = \"trimap\"\n",
    "\n",
    "if clustering == \"trimap\":\n",
    "    reducer = trimap.TRIMAP()\n",
    "elif clustering == \"umap\":\n",
    "    reducer = umap.UMAP()\n",
    "elif clustering == \"param_umap\":\n",
    "    reducer = ParametricUMAP()\n",
    "elif clustering == \"pca\":\n",
    "    reducer = PCA(n_components=2)\n",
    "elif clustering == \"tsne\":\n",
    "    reducer = TSNE(n_components=2, init=\"pca\", random_state=0)\n",
    "reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receiver_x, receiver_y = get_xy(receiver_data)\n",
    "receiver_x, receiver_y = receiver.buffer.get_data(len(receiver.buffer))\n",
    "sender_x, sender_y = get_xy(sender_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_x.shape, sender_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"cifar10\":\n",
    "    features = {\"feats\": []}\n",
    "    cifar10_to_backbone_embedding(backbone, receiver_x)\n",
    "    receiver_x = torch.cat(features['feats'])\n",
    "    features = {\"feats\": []}\n",
    "    cifar10_to_backbone_embedding(backbone, sender_x)\n",
    "    sender_x = torch.cat(features['feats'])\n",
    "    # print(\"shape:\", receiver_x.shape)\n",
    "    print(\"shape:\", receiver_x.shape, sender_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_x = to_features(receiver_x)\n",
    "# print(\"shape:\", receiver_x.shape)\n",
    "sender_x = to_features(sender_x)\n",
    "print(\"shape:\", receiver_x.shape, sender_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_x = torch.cat([receiver_x, sender_x])\n",
    "joint_y = torch.cat([receiver_y, sender_y])\n",
    "\n",
    "# joint_x = torch.cat([receiver_x])\n",
    "# joint_y = torch.cat([receiver_y])\n",
    "joint_x.shape, joint_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://umap-learn.readthedocs.io/en/latest/supervised.html\n",
    "reducer.fit_transform(joint_x.cpu().numpy(), y=joint_y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the embedding\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "for i in range(len(joint_y)):\n",
    "    if joint_y[joint_y == i].shape[0] > 0:\n",
    "        ax.scatter(reducer.embedding_[joint_y == i, 0], reducer.embedding_[joint_y == i, 1], label=i)\n",
    "ax.legend();\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# red_colors = [\"red\", \"darkred\", \"salmon\", \"chocolate\"]\n",
    "# blue_colors = [\"blue\", \"skyblue\", \"navy\"]\n",
    "# receiver_embed = reducer.embedding_[:len(receiver_y)]\n",
    "# sender_embed = reducer.embedding_[len(receiver_y):]\n",
    "\n",
    "# for i in range(10):\n",
    "#     # plot receiver with bluish color and sender with reddish color\n",
    "#     if len(receiver_y[receiver_y == i]) > 0:\n",
    "#         ax.scatter(receiver_embed[receiver_y == i, 0], receiver_embed[receiver_y == i, 1],\n",
    "#                         label=f\"receiver y={i}\", color=blue_colors.pop())\n",
    "\n",
    "#     if len(sender_y[sender_y == i]) > 0:\n",
    "#         ax.scatter(sender_embed[sender_y == i, 0], sender_embed[sender_y == i, 1],\n",
    "#                         label=f\"sender y={i}\", color=red_colors.pop())\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sharing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:13:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ce37e01e4e25dad4acdf5a835a9fd4c67494d5c7616f20984ba493f320ae940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
